# Сервис вычисления квадратных корней

## Зависимости

* [poetry](https://python-poetry.org/docs/#installation)
* [docker & docker-compose](https://docs.docker.com/get-docker/)
* GNU make, bash
* [direnv](https://direnv.net/) (опционально)

## Первичная настройка, тесты, ещё тесты, запуск всего проекта целиком

Склонировать проект. Конфигурация осуществляется через премеменные среды, все необходимые переменные (с примерами значений) перечислены в файле `env.sample`, рекоммендуется скопировать его в `env.local` и там уже изменять по необходимости - это файл заигнорен, в отличие от `env.sample`. Переменные необходимо экспортировать в текущий shell. Сделать это можно, например, так:

```console
$ set -o allexport
$ source env.local
$ set +o allexport
```

Можно так же прибегнуть к помощи каких-нибудь утилит, делающих это автоматически. Например, с `direnv` это можно сделать так:

```console
$ echo dotenv env.local >> .envrc
$ dotenv allow .
```

Теперь, все переменные перечисленные в `env.local`, будут экспортироваться/выгружаться автоматически при заходе/выходе в директорию проекта.

Далее, установить зависимости:

```console
$ poetry install
```

Всё готово для запуска тестов:

```console
$ make .check  # именно так, с точкой
```

Одако, на самом деле это не все тесты ))) А только те, что не помечены маркером `integration` - быстрые, детерменированные, юнит!

Для запуска "интеграционных" тестов требуется дополнительная настройка. К сожалению, полностью автоматизировать её не удалось.

Собрать docker образы для compose:

```console
$ make .docker-compose-build  # 1
```

Запустить севрисы-зависимости:

```console
$ make docker-compose-up-deps  # 2
```

Настроить БД, очередь:

```console
$ make setup-db setup-rabbitmq  # 3
```

Поднять минимум один воркер:

```console
$ make docker-compose-up-one-worker
```

Всё, теперь можно запускать _все_ тесты:

```console
$ make .check-full
```

Так же можно поднять всё целиком, но для этого всё равно необходимо предварительно выполнить шаги 1, 2 и 3:

```console
# make docker-compose-up
```

HTTP API находится на порту `8080`, схемы запросов и ответов можно посмотреть в `computations/http/schemas`.

"Потушить" всё можно следующей командой. БД, очередь будут удалены, так что перед новым запуском потребуется всё заново иницилизировать (кроме, возможно, образа docker): шаги 2, 3.

```console
# make docker-compose-down
```

## Некоторые соображения

При реализации этого сервиса я старался максимально наглядно отразить принципы, которыми я руководствуюсь при продакшн-разработке.

* Я посторался применить подход DDD (Evans), однако на таком маленьком сервисе это не то, чтобы очень нужно, но ещё и к тому же сложно - сервис-то тривиальный ("искусственный"). В общем, этот подход сводится к тому, чтобы максимально чётко выделить модель предметной области - тут этот некие вычисления - и изолировать её от инфраструктуры (всё, что касается технической стороны: БД, очереди, REST API и т. д.). На сколько у меня это получилось - решать вам :) Из этого так же следует несколько интересных особенностей. Как видите, я не использовал ORM, а работал с БД напрямую - соединения, транзакции - подробнее об этом ниже. Так же, на таком простом примере код получился несколько "избыточный" (или даже "развесистый") - много уровней, классов - хотя по факту сами вычисления производит всего лишь один малюсенький класс. Но, я это сделал сознательно, опять таки, для болшей выразительности самого подхода.

* ORM я - снова сознательно - не использовал. Когда есть хорошо изолированная модель (предметной области), она как правило плохо "ложится" на ORM. И у большинства тут возникает соблазн от ORM вообще отказаться, мол: от этого только выиграем, ведь нам не нужна вся эта сложная машинерия. Будем писать старые добрые простые объекты, сами их сериализовать, и обычными запросиками в БД писать. Особенно соблазн велик, когда в модели присутствуют ярко выраженные ***агрегаты*** (по Эвансу). Я попытался проиллюстировать, что бывает, когда выбирают этот путь. Да, модельки действительно получаются простые. Сериализацию написать тоже ничего сложного (кроме того, что это рутина). Однако инфраструктурный слой неизбежно просачивается в модель (предметной области), ведь с горяча забываются такие штуки, как синхронизация данных, вычитанных из БД, и хранящихся в базе (пресловутый трэкинг первичных ключей), relationship'ы, и прочее, что ORM за нас делает "из коробки" автоматом. Таким путём рано или поздно можно дойти до самописной ORM, которая будет при этом забагованная, медленная и не консистентная. Однако это не значит, что такой подход отказа от ORM - плохой :)

* Бета-версия алхимии (SQLAlchemy). Ещё одна штука, которую я старался показать максимально наглядно. Давно мне не давал покоя это вопрос. Так вот, в общем случае, для того чтобы инфраструктурный слой покрывать тестами, живая база данных вовсе не нужна. Если подумать, то можо прийти к выводу, что единственная ответственность всяких там Object Relation Mapper'ов, репозиториев и т. д. - это построение *правильных* SQL-запросов. А для этого эти самые запросы вовсе не обязательно в базу отправлять - достаточно просто сравнить их с эталонным запросом. Так вот, до недавнего времени в алхимии это сделать было не возможно по причине того, что все SQL constructs нельзя было сравнивать друг с другом. Вот, в бета-версии эту возможность как раз реализовали. Подробнее можно посмотреть тут: https://github.com/sqlalchemy/sqlalchemy/issues/5562 (по поводу целесообразности такого подхода к тестированию там тоже есть). Как результат - в этом проекте все тесты, кроме одного - вообще не требуют запущенной базы (а ведь ещё и миграции накатывать надо как-то).

* Тестирование и (а-ля) CI/CD. Проблема "само-поднимаемости" и "само-настраиваемости" разрабатываемого сервиса меня занимала всегда. Ведь от того, на сколько легко сервис поднимается на localhost'е зависит и то, на сколько легко он будет подниматься в тестовых, интеграционных, боевых окружениях. К сожалению, выработать решение, когда вот прямо одной командой (!) всё действительно поднималось у меня пока до сих пор не получилось. Всегда есть некоторая ручная работа - какие-то скрипты самопальные, магические команды, вбиваемые в консоль. Всегда нет, нет - да и кто-нибудь забудет накатить миграции, поднять сервис зависимый - очередь, там, хранилище файлов какое-то и т. д. Пока что не спасает и Docker, и docker-compose, и иже с ними. Все эти инструменты чрезвычайно трудно интегрируются в процессы разработки - так, чтобы оно "само работало". Но, безусловно, это упрощает жизнь.

Конкретно в этом проекте, я опять же, поптытался максимально приблизиться к сценарию "поднять проект на локалхосте одной командой" - где-то с помощью соглашений (например, дефолтные credentials к различным сервисам - если посмотреть, они все типовые), где-то с помощью "скриптов" (Make). Но получилось всё равно так себе. Всё ещё есть куча ограничений, например, docker-compose поддерживает зависимости между сервисами, но толку от них не много, так как вся поддержка - это просто очерёдность запуска. Она, в общем-то, не гарантирует, что зависимый сервис будет готов к моменту запуска зависящего - для этго требуется readiness probe, но docker-compose не поддерживет их "из коробки". В общем, как всегда :D

* Ну и, наконец, Make. Как бы он мне не нравился, но по факту - альтернативы нет. Я, опять же, давно пытаюсь найти некий generic task runner/project automation tool, но ничего достойного нет. Либо - просто тот же Make с другим синтаксисом, либо через чур "навороченный" раннер, поддерживающий всё и вся, ещё и с плагинами (писать их надо, правда, на Java). Фундаментальное ограничение make - он отслеживает зависимости только на основании файлов и их временных меток, а хотелось бы объявлять в качестве зависимостей, напрмер открытые порты - ну вы уловили суть, думаю. С другой стороны, фундаментальное преимущество make - он просто выполняет команды в шелле, зачастую именно это только и нужно, ибо не ко всему ещё есть интерфейсы прямо из всех возможных языков программирования. А хотелось бы, чтобы этот гипотетический automation tool был, что называется, language agnostic - на всех проектах использовать тогда можно будет, админы/девопсы/SREшники потом спасибо скажут. Вот попробуйте, скажем, создать базу данных из питона - готов побиться об заклад, что это будет аналог `subprocess.run('createdb')` - зачем только тогда Python?. Но почему-то именно с синтаксисом (читай - запуском команд в shell) все стремятся бороться, создавая свой собственный клон make. Вот и получается, что от чего бежали, к тому и пришли - Make.
